{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41cd338-d4ce-479c-bda5-44f669f934ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai \n",
    "import json \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from functions_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1036cf02-9a5c-4f3e-9bce-2358831f69be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67cbc924-a50a-401d-9c1e-a2a4e2082da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context is a passage discussing the importance of reading and writing. It highlights that reading not only imparts knowledge but also teaches writing. The passage emphasizes that writing is a way to convey ideas and also a means of discovering new things. It suggests that writing is essential for solving complex problems and developing ideas. The author asserts that good reading and writing skills are interconnected and vital for effective thinking.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "summarize the context\"\"\"\n",
    "\n",
    "create_connection()\n",
    "read_pdf('/Users/galampley/Desktop/ChatYourDocs/TheNeedToRead_Graham.pdf')\n",
    "learn_document('/Users/galampley/Desktop/ChatYourDocs/TheNeedToRead_Graham.pdf', 'TheNeedToRead_Graham', 'pdf')\n",
    "original_answer = Answer_from_documents(query)\n",
    "original_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31dc1de7-0b9e-4322-90a0-d82d254e9fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "necessary_info = {\n",
    "    'query': query,\n",
    "    'context': read_pdf('/Users/galampley/Desktop/ChatYourDocs/TheNeedToRead_Graham.pdf')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6070a4bb-5321-4b39-98e1-a2d5a6cf8122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_with_rubric(test_set, original_answer):\n",
    "\n",
    "    original_query = test_set['query']\n",
    "    context = test_set['context']\n",
    "    completion = original_answer\n",
    "    \n",
    "    system_message = \"\"\"\\\n",
    "    You are an assistant that evaluates how well the agent \\\n",
    "    answers a user question by looking at the context that the \\\n",
    "    agent is using to generate its response. \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\\\n",
    "    You are evaluating a submitted answer to a question based on the context \\\n",
    "    that the agent uses to answer the question.\n",
    "    Here is the data:\n",
    "        [BEGIN DATA]\n",
    "        ************\n",
    "        [Question]: {original_query}\n",
    "        ************\n",
    "        [Context]: {context}\n",
    "        ************\n",
    "        [Submission]: {completion}\n",
    "        ************\n",
    "        [END DATA]\n",
    "\n",
    "    Compare the factual content of the submitted answer with the context. \\\n",
    "    Ignore any differences in style, grammar, or punctuation.\n",
    "    Answer the following questions:\n",
    "        - Is the Assistant response based only on the context provided? (Y or N)\n",
    "        - Does the answer include information that is not provided in the context? (Y or N)\n",
    "        - Is there any disagreement between the response and the context? (Y or N)\n",
    "        - Count how many questions the user asked. (output a number)\n",
    "        - For each question that the user asked, is there a corresponding answer to it?\n",
    "        Question 1: (Y or N)\n",
    "        Question 2: (Y or N)\n",
    "        ...\n",
    "        Question N: (Y or N)\n",
    "        - Of the number of questions asked, how many of these questions were addressed by the answer? (output a number)\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "\n",
    "    response = get_completion_from_messages(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08dca2de-010b-475d-98c3-6e622814414f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Is the Assistant response based only on the context provided? (Y or N)\n",
      "Y\n",
      "\n",
      "- Does the answer include information that is not provided in the context? (Y or N)\n",
      "N\n",
      "\n",
      "- Is there any disagreement between the response and the context? (Y or N)\n",
      "N\n",
      "\n",
      "- Count how many questions the user asked. (output a number)\n",
      "1\n",
      "\n",
      "- For each question that the user asked, is there a corresponding answer to it?\n",
      "Question 1: Y\n",
      "\n",
      "- Of the number of questions asked, how many of these questions were addressed by the answer? (output a number)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "evaluation_output = eval_with_rubric(necessary_info, original_answer)\n",
    "print(evaluation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704991c-68e5-4285-a677-46f33ed7a5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new_env]",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
